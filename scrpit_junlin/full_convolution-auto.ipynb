{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4a801d-6296-4268-9f81-edb9e2313752",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Python Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad95307a-c46b-4e2d-a129-665b604aad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gestion fichier modeles pythons\n",
    "import os , sys            \n",
    "workpath = sys.path[0]\n",
    "\n",
    "sys.path.append(f'{workpath}\\fidle-env\\lib\\site-packages')\n",
    "\n",
    "#modules utilitaires\n",
    "import random as r\n",
    "import numpy as np\n",
    "import time \n",
    "import json\n",
    "import fidle\n",
    "import fidle.pwk as pwk   \n",
    "#traitement image\n",
    "import matplotlib.pyplot as plt   \n",
    "from skimage import io \n",
    "import pandas as pd\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "#module IA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3250092b-f23a-405f-9725-444508fcb644",
   "metadata": {},
   "source": [
    "## les diffs choix de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b002847d-c87a-4e78-b3b4-3fc980feeb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = f'{workpath}\\datasheet\\mmClasses-DataBase-IMG\\mmClasses-DataBase-IMG\\data_64'\n",
    "descri_datapath = [datapath, 'img_64']\n",
    "run_dir=\"E:\\INSA-cour\\A4A\\Projet_multi\\work-dictory\\\\trained_model\\model_64\"\n",
    "fidle.utils.mkdir(run_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ead109b-f744-4b83-864a-9d29e8a339ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters for CNN and DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c95a8e-3516-4127-b112-91ba1310b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pourcentage du dataset à load\n",
    "scale = 1  \n",
    "\n",
    "batch_size    = 64\n",
    "epochs        = 10\n",
    "fit_verbosity = 1\n",
    "\n",
    "index_to_class = [\"CUBO\",\"DEC\",\"FCC\",\"FCC-sphere\",\"HCP-sphere\",\"ICO\",\"MnBeta_sphere\",\"OH\",\"RTD\",\"BCC\",\"DODECA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118a8ed-37b1-45e8-82ee-fb8f5e552158",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f18a92-c53e-43a1-b62e-4188e1ad0546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset (filepath : str):\n",
    "    \"\"\"entrée : chemin vers le dossier contenant la BDD\n",
    "    sortie : listes des images et leur classes respectives, mis à l'échelle (scale) et mélangées\"\"\"\n",
    "    \n",
    "    L = os.listdir(filepath)   #liste contenenant le nom (en .jpg) de toutes les images\n",
    "    nb_files = len(L)\n",
    "    nb_files2load = round(nb_files*scale)\n",
    "    size = np.shape(io.imread(f'{filepath}/{L[0]}' , as_gray = True))\n",
    "    \n",
    "    #initialisation listes sortie\n",
    "    img = np.zeros ( (nb_files2load , size[0] , size[1]) , dtype = np.float16 )\n",
    "    ID  = np.zeros ( nb_files2load , dtype = np.int8)\n",
    "   \n",
    "    for i in range (nb_files2load):\n",
    "        \n",
    "        random_index = r.randint(0 , nb_files - i - 1)\n",
    "        img[i] = io.imread (f'{filepath}/{L[random_index]}',as_gray = True)\n",
    "        ID [i] = int (L[random_index][:3]) - 1\n",
    "        L.pop(random_index)\n",
    "        \n",
    "    N = len(img)\n",
    "    nb_img = N\n",
    "    img_train = img[0:round(N*0.8)]\n",
    "    img_test  = img[round(N*0.8):]\n",
    "    ID_train = ID[0:round(N*0.8)]\n",
    "    ID_test  = ID[round(N*0.8):]   \n",
    "        \n",
    "    return img_train,img_test,ID_train,ID_test,nb_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09829ea-64be-467c-a306-bee2323d1a38",
   "metadata": {},
   "source": [
    "## afficher qq images de dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417c603-188c-44d5-8e6c-12cec02529cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for i in range(4):\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(img_train[i], cmap =\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    ax.text(6,10,index_to_class[ID_train[i]], bbox={'facecolor': 'white', 'pad': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a21a969-2e4b-43d1-b81a-e7dbccd98fe8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Models creations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371cfdd-3c96-4d0c-84f1-59812bdde01e",
   "metadata": {},
   "source": [
    "## comparaison des functions d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859844b0-8792-4819-b52b-3e30776ca463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model1(lx,ly): \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( keras.layers.Dense(1000, activation='relu'))\n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    \n",
    "    code_model='1'\n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)\n",
    "    return model, model_name, code_model\n",
    "\n",
    "\n",
    "\n",
    "def create_model1_DNNsigmod(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.sigmoid))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "              \n",
    "    code_model='1_DNNsigmod'\n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)\n",
    "              \n",
    "    return model, model_name, code_model\n",
    "\n",
    "\n",
    "def create_model1_DNNtanh(lx,ly): \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.tanh))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNtanh'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model\n",
    "\n",
    "def create_model1_DNNsoftsign(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "              \n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.softsign))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNsoftsign'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model\n",
    "\n",
    "\n",
    "def create_model1_DNNelu(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.elu))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNelu'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model              \n",
    "\n",
    "\n",
    "              \n",
    "def create_model1_DNNselu(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.selu))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNselu'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model                \n",
    "              \n",
    "def create_model1_DNNsoftplus(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.softplus))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNsoftplus'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e4b86bd-cd6d-420f-a283-b72102b21adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model1_DNNsoftplus(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.softplus))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNsoftplus'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model \n",
    "\n",
    "def create_model1_DNNelu(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.elu))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNelu'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model \n",
    "\n",
    "\n",
    "def create_model1_DNNselu(lx,ly): #\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add( keras.layers.Conv2D(32, (3,3),   activation='relu', input_shape=(lx,ly,1)))\n",
    "    model.add( keras.layers.MaxPooling2D((3, 3)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add( keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add( keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add( keras.layers.Flatten()) \n",
    "    model.add( layers.Dense(1000))\n",
    "    model.add( layers.Activation(activations.selu))          \n",
    "    model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "    model.add( keras.layers.Dense(11, activation='softmax'))\n",
    "    code_model='1_DNNselu'  \n",
    "    model_name = 'e'+str(epochs)+'bs'+str(batch_size)+'sc'+str(scale)+'code'+str(code_model)          \n",
    "    return model, model_name, code_model   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06856142-3d21-47a8-b713-5b8a5040db30",
   "metadata": {},
   "source": [
    "## qq variable a entrer dans les foncitons suivants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee00af3-bac1-4ad3-a331-cd35678497c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# les entree pour le dataset 64\n",
    "datasets = [descri_datapath]\n",
    "with_datagen  = False\n",
    "tag_id = \"fonc_acti\"\n",
    "#models = ['create_model1','create_model1_DNNsigmod','create_model1_DNNtanh','create_model1_DNNsoftsign','create_model1_DNNelu','create_model1_DNNselu','create_model1_DNNsoftplus']\n",
    "models = ['create_model1_DNNsoftplus','create_model1_DNNselu','create_model1_DNNelu']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762c38b-b783-41bf-b6e8-45bba5c0ada4",
   "metadata": {},
   "source": [
    "## Multiple datasets, multiple models ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed889bec-a219-4311-8094-f62ca32b9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_run(datasets, models, datagen=None,\n",
    "              scale=1, batch_size=64, epochs=16, \n",
    "              fit_verbosity=0, tag_id='last'):\n",
    "    \"\"\"\n",
    "    Launches a dataset-model combination\n",
    "    args:\n",
    "        enhanced_dir   : Directory of the enhanced datasets\n",
    "        datasets       : List of dataset (whitout .h5)\n",
    "        models         : List of model like { \"model name\":get_model(), ...}\n",
    "        datagen        : Data generator or None (None)\n",
    "        scale          : % of dataset to use.  1 mean all. (1)\n",
    "        batch_size     : Batch size (64)\n",
    "        epochs         : Number of epochs (16)\n",
    "        fit_verbosity  : Verbose level (0)\n",
    "        tag_id         : postfix for report, logs and models dir (_last)\n",
    "    return:\n",
    "        report        : Report as a dict for Pandas.\n",
    "    \"\"\"  \n",
    "    # ---- Logs and models dir\n",
    "    #\n",
    "    os.makedirs(f'{run_dir}/logs_{tag_id}',   mode=0o750, exist_ok=True)\n",
    "    os.makedirs(f'{run_dir}/models_{tag_id}', mode=0o750, exist_ok=True)\n",
    "    \n",
    "    # ---- Columns of output\n",
    "    #\n",
    "    output={}\n",
    "    output['Dataset'] = []\n",
    "    output['Size']    = []\n",
    "    for m in models:\n",
    "        output[m+'_Accuracy'] = []\n",
    "        output[m+'_Duration'] = []\n",
    "\n",
    "    # ---- Let's go\n",
    "    #\n",
    "    for d_name in datasets:\n",
    "        print(\"\\nDataset : \",d_name[0])\n",
    "        \n",
    "        # ---- Read dataset\n",
    "        img_train,img_test,ID_train,ID_test, d_size = read_dataset(d_name[0])\n",
    "        d_name = d_name[1]\n",
    "        output['Dataset'].append(d_name)\n",
    "        output['Size'].append(d_size)\n",
    "        print(len(img_train))\n",
    "        print(len(ID_train))\n",
    "        # ---- Rescale c'est pas vraiment necessaire\n",
    "        ##img_train,ID_train,img_test,ID_test = pwk.rescale_dataset(img_train,ID_train,img_test,ID_test, scale=scale)\n",
    "        \n",
    "        # ---- Get the shape\n",
    "        (n,lx,ly) = img_train.shape\n",
    "\n",
    "        # ---- For each model\n",
    "        for m_function in models:\n",
    "            \n",
    "            # ---- get model\n",
    "            try:\n",
    "                # ---- get function by name\n",
    "                m_function=globals()[m_function]\n",
    "                model, m_name, code_model=m_function(lx,ly)\n",
    "                \n",
    "                print(\"    Run model {}  : \".format(code_model), end='')\n",
    "                # ---- Compile it\n",
    "                model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "                # ---- Callbacks tensorboard\n",
    "                log_dir = f'{run_dir}/logs_{tag_id}/tb_{d_name}_{m_name}'\n",
    "                tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                # ---- Callbacks bestmodel\n",
    "                save_dir = f'{run_dir}/models_{tag_id}/model_{d_name}_{m_name}.h5'\n",
    "                bestmodel_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_dir, verbose=0, monitor='accuracy', save_best_only=True)\n",
    "                # ---- Train\n",
    "                start_time = time.time()\n",
    "                if datagen==None:\n",
    "                    # ---- No data augmentation (datagen=None) --------------------------------------\n",
    "                    history = model.fit(img_train, ID_train,\n",
    "                                        batch_size      = batch_size,\n",
    "                                        epochs          = epochs,\n",
    "                                        verbose         = fit_verbosity,\n",
    "                                        validation_data = (img_test, ID_test),\n",
    "                                        callbacks       = [tensorboard_callback, bestmodel_callback])\n",
    "                else:\n",
    "                    # ---- Data augmentation (datagen given) ----------------------------------------\n",
    "                    datagen.fit(x_train)\n",
    "                    history = model.fit(datagen.flow(img_train, ID_train, batch_size=batch_size),\n",
    "                                        steps_per_epoch = int(len(img_train)/batch_size),\n",
    "                                        epochs          = epochs,\n",
    "                                        verbose         = fit_verbosity,\n",
    "                                        validation_data = (img_test, ID_test),\n",
    "                                        callbacks       = [tensorboard_callback, bestmodel_callback])\n",
    "                    \n",
    "                # ---- Result\n",
    "                end_time = time.time()\n",
    "                duration = end_time-start_time\n",
    "                accuracy = max(history.history[\"val_accuracy\"])*100\n",
    "                #\n",
    "                #output[m+'_Accuracy'].append(accuracy)\n",
    "                output[m+'_Accuracy'] = accuracy\n",
    "                #output[m+'_Duration'].append(duration)\n",
    "                output[m+'_Duration'] = duration\n",
    "                print(f\"Accuracy={accuracy: 7.2f}    Duration={duration: 7.2f}\")\n",
    "            except:\n",
    "                raise\n",
    "                output[m+'_Accuracy'].append('0')\n",
    "                output[m+'_Duration'].append('999')\n",
    "                print('-')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b497c82-e1b9-49cd-89e8-eac20d57eabb",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c63152-81e5-4563-83ca-956d8b9687b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Run --------------------------------------------------\n",
      "\n",
      "Dataset :  E:\\INSA-cour\\A4A\\Projet_multi\\work-dictory\\datasheet\\mmClasses-DataBase-IMG\\mmClasses-DataBase-IMG\\data_64\n",
      "16032\n",
      "16032\n",
      "    Run model 1_DNNsoftplus  : Epoch 1/10\n",
      "251/251 [==============================] - 29s 114ms/step - loss: 2.1720 - accuracy: 0.2172 - val_loss: 1.9614 - val_accuracy: 0.2722\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 1.4151 - accuracy: 0.4396 - val_loss: 1.0109 - val_accuracy: 0.5803\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 30s 119ms/step - loss: 1.0003 - accuracy: 0.5935 - val_loss: 0.8141 - val_accuracy: 0.6749\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 33s 132ms/step - loss: 0.7841 - accuracy: 0.6782 - val_loss: 0.6167 - val_accuracy: 0.7400\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 31s 122ms/step - loss: 0.6428 - accuracy: 0.7355 - val_loss: 0.4641 - val_accuracy: 0.8129\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 28s 113ms/step - loss: 0.5331 - accuracy: 0.7818 - val_loss: 0.3831 - val_accuracy: 0.8573\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.4645 - accuracy: 0.8096 - val_loss: 0.3769 - val_accuracy: 0.8351\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 28s 111ms/step - loss: 0.4058 - accuracy: 0.8356 - val_loss: 0.2906 - val_accuracy: 0.8862\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 28s 112ms/step - loss: 0.3661 - accuracy: 0.8527 - val_loss: 0.2148 - val_accuracy: 0.9251\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.3173 - accuracy: 0.8750 - val_loss: 0.2100 - val_accuracy: 0.9192\n",
      "Accuracy=  92.51    Duration= 293.03\n",
      "    Run model 1_DNNselu  : Epoch 1/10\n",
      "251/251 [==============================] - 29s 116ms/step - loss: 1.7780 - accuracy: 0.3249 - val_loss: 1.0772 - val_accuracy: 0.5861\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.9888 - accuracy: 0.5991 - val_loss: 0.7015 - val_accuracy: 0.7213\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.6971 - accuracy: 0.7236 - val_loss: 0.5841 - val_accuracy: 0.7904\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.5641 - accuracy: 0.7778 - val_loss: 0.4340 - val_accuracy: 0.8298\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 29s 117ms/step - loss: 0.4564 - accuracy: 0.8199 - val_loss: 0.2883 - val_accuracy: 0.9087\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 31s 124ms/step - loss: 0.3872 - accuracy: 0.8451 - val_loss: 0.3624 - val_accuracy: 0.8653\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 30s 118ms/step - loss: 0.3451 - accuracy: 0.8670 - val_loss: 0.1990 - val_accuracy: 0.9349\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.3001 - accuracy: 0.8869 - val_loss: 0.2379 - val_accuracy: 0.9162\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 31s 123ms/step - loss: 0.2740 - accuracy: 0.8977 - val_loss: 0.1434 - val_accuracy: 0.9486\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 31s 123ms/step - loss: 0.2356 - accuracy: 0.9095 - val_loss: 0.1769 - val_accuracy: 0.9356\n",
      "Accuracy=  94.86    Duration= 296.97\n",
      "    Run model 1_DNNelu  : Epoch 1/10\n",
      "251/251 [==============================] - 29s 113ms/step - loss: 1.8287 - accuracy: 0.3046 - val_loss: 1.1356 - val_accuracy: 0.5339\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 29s 117ms/step - loss: 1.0091 - accuracy: 0.5908 - val_loss: 0.7030 - val_accuracy: 0.7133\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 29s 116ms/step - loss: 0.7244 - accuracy: 0.7075 - val_loss: 0.5331 - val_accuracy: 0.7834\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 31s 123ms/step - loss: 0.5619 - accuracy: 0.7759 - val_loss: 0.3514 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 32s 127ms/step - loss: 0.4577 - accuracy: 0.8194 - val_loss: 0.2769 - val_accuracy: 0.9024\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 29s 115ms/step - loss: 0.3821 - accuracy: 0.8493 - val_loss: 0.2432 - val_accuracy: 0.9099\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 30s 118ms/step - loss: 0.3336 - accuracy: 0.8722 - val_loss: 0.2254 - val_accuracy: 0.9192\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 31s 122ms/step - loss: 0.3006 - accuracy: 0.8852 - val_loss: 0.2437 - val_accuracy: 0.9069\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 29s 117ms/step - loss: 0.2690 - accuracy: 0.8970 - val_loss: 0.1738 - val_accuracy: 0.9349\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 30s 118ms/step - loss: 0.2379 - accuracy: 0.9091 - val_loss: 0.1691 - val_accuracy: 0.9359\n",
      "Accuracy=  93.59    Duration= 298.63\n",
      "\n",
      "Report saved as  E:\\INSA-cour\\A4A\\Projet_multi\\work-dictory\\trained_model\\model_64/report_fonc_acti.json\n",
      "\n",
      "Duration :  00:18:12 331ms\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pwk.chrono_start()\n",
    "\n",
    "print('\\n---- Run','-'*50)\n",
    "\n",
    "\n",
    "# ---- Data augmentation or not\n",
    "#\n",
    "if with_datagen :\n",
    "    datagen = keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,\n",
    "                                                           featurewise_std_normalization=False,\n",
    "                                                           width_shift_range=0.1,\n",
    "                                                           height_shift_range=0.1,\n",
    "                                                           zoom_range=0.2,\n",
    "                                                           shear_range=0.1,\n",
    "                                                           rotation_range=10.)\n",
    "else:\n",
    "    datagen=None\n",
    "    \n",
    "# ---- Run\n",
    "#\n",
    "output = multi_run(datasets, \n",
    "                   models,\n",
    "                   datagen       = datagen,\n",
    "                   scale         = scale,\n",
    "                   batch_size    = batch_size,\n",
    "                   epochs        = epochs,\n",
    "                   fit_verbosity = fit_verbosity,\n",
    "                   tag_id        = tag_id)\n",
    "\n",
    "# ---- Save report\n",
    "#\n",
    "report={}\n",
    "report['output']=output\n",
    "report['description'] = f'scale={scale} batch_size={batch_size} epochs={epochs} data_aug={with_datagen}'\n",
    "\n",
    "report_name=f'{run_dir}/report_{tag_id}.json'\n",
    "\n",
    "with open(report_name, 'w') as file:\n",
    "    json.dump(report, file, indent=4)\n",
    "\n",
    "print('\\nReport saved as ',report_name)\n",
    "\n",
    "pwk.chrono_show()\n",
    "print('-'*59)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d57b10d-3b48-4b96-a85d-8ca8f6607d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dataset': ['img_64'], 'Size': [20040], 'create_model1_DNNsoftplus_Accuracy': [], 'create_model1_DNNsoftplus_Duration': [], 'create_model1_DNNselu_Accuracy': [], 'create_model1_DNNselu_Duration': [], 'create_model1_DNNelu_Accuracy': 93.58782172203064, 'create_model1_DNNelu_Duration': 298.6322069168091}\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc34b4ff-4711-4e71-ad22-a83dd470f908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6582c42f-798c-4ee4-b422-e4202e28b268",
   "metadata": {},
   "source": [
    "## show report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5807c0-9280-45e6-98b9-c83193db1ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dir = run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f6b7f-873e-4844-82e9-790cd6a3c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = (s == s.max())\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "def show_report(file):\n",
    "    # ---- Read json file\n",
    "    with open(file) as infile:\n",
    "        dict_report = json.load( infile )\n",
    "    output      = dict_report['output']\n",
    "    description = dict_report['description']\n",
    "    # ---- about\n",
    "    pwk.subtitle(f'Report : {Path(file).stem}')\n",
    "    print(    \"Desc.  : \",description,'\\n')\n",
    "    # ---- Create a pandas\n",
    "    report       = pd.DataFrame (output)\n",
    "    col_accuracy = [ c for c in output.keys() if c.endswith('Accuracy')]\n",
    "    col_duration = [ c for c in output.keys() if c.endswith('Duration')]\n",
    "    # ---- Build formats\n",
    "    lambda_acc = lambda x : '{:.2f} %'.format(x) if (isinstance(x, float)) else '{:}'.format(x)\n",
    "    lambda_dur = lambda x : '{:.1f} s'.format(x) if (isinstance(x, float)) else '{:}'.format(x)\n",
    "    formats = {'Size':'{:.2f} Mo'}\n",
    "    for c in col_accuracy:   \n",
    "        formats[c]=lambda_acc\n",
    "    for c in col_duration:\n",
    "        formats[c]=lambda_dur\n",
    "    t=report.style.highlight_max(subset=col_accuracy).format(formats).hide_index()\n",
    "    display(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647edae-2c97-47c6-8ef3-d7c6e68fe448",
   "metadata": {},
   "source": [
    "## Step 3 - Reports display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950b1e7-3537-4a3a-a91a-465eb46e9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(f'{report_dir}/*.json'):\n",
    "    show_report(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060c78b8-153f-40ae-8694-c5874e6c3181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
